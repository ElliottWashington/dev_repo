{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: MDB, Response: {'meta': {'symbol': 'MDB', 'interval': '1day', 'currency': 'USD', 'exchange_timezone': 'America/New_York', 'exchange': 'NASDAQ', 'mic_code': 'XNMS', 'type': 'Common Stock'}, 'values': [{'datetime': '2023-06-02', 'open': '380.39001', 'high': '397.97989', 'low': '370.00000', 'close': '373.78320', 'volume': '7218753'}], 'status': 'ok'}\n",
      "Symbol: LRCX, Response: {'meta': {'symbol': 'LRCX', 'interval': '1day', 'currency': 'USD', 'exchange_timezone': 'America/New_York', 'exchange': 'NASDAQ', 'mic_code': 'XNGS', 'type': 'Common Stock'}, 'values': [{'datetime': '2023-06-02', 'open': '618.98499', 'high': '621.98999', 'low': '608.05389', 'close': '614.73999', 'volume': '618287'}], 'status': 'ok'}\n",
      "Symbol: CRWD, Response: {'meta': {'symbol': 'CRWD', 'interval': '1day', 'currency': 'USD', 'exchange_timezone': 'America/New_York', 'exchange': 'NASDAQ', 'mic_code': 'XNGS', 'type': 'Common Stock'}, 'values': [{'datetime': '2023-06-02', 'open': '158.53000', 'high': '159.39999', 'low': '153.00999', 'close': '154.47000', 'volume': '4908974'}], 'status': 'ok'}\n",
      "Symbol: LULU, Response: {'meta': {'symbol': 'LULU', 'interval': '1day', 'currency': 'USD', 'exchange_timezone': 'America/New_York', 'exchange': 'NASDAQ', 'mic_code': 'XNGS', 'type': 'Common Stock'}, 'values': [{'datetime': '2023-06-02', 'open': '378.23001', 'high': '386.32999', 'low': '366.32001', 'close': '367.63501', 'volume': '7016822'}], 'status': 'ok'}\n",
      "Symbol: TGT, Response: {'meta': {'symbol': 'TGT', 'interval': '1day', 'currency': 'USD', 'exchange_timezone': 'America/New_York', 'exchange': 'NYSE', 'mic_code': 'XNYS', 'type': 'Common Stock'}, 'values': [{'datetime': '2023-06-02', 'open': '131.23700', 'high': '133.25000', 'low': '130.59010', 'close': '132.64999', 'volume': '4638484'}], 'status': 'ok'}\n",
      "Symbol: SVIX, Response: {'meta': {'symbol': 'SVIX', 'interval': '1day', 'currency': 'USD', 'exchange_timezone': 'America/New_York', 'exchange': 'CBOE', 'mic_code': 'BATS', 'type': 'ETF'}, 'values': [{'datetime': '2023-06-02', 'open': '22.36610', 'high': '22.79050', 'low': '22.20000', 'close': '22.72000', 'volume': '1488689'}], 'status': 'ok'}\n",
      "Symbol: HUM, Response: {'meta': {'symbol': 'HUM', 'interval': '1day', 'currency': 'USD', 'exchange_timezone': 'America/New_York', 'exchange': 'NYSE', 'mic_code': 'XNYS', 'type': 'Common Stock'}, 'values': [{'datetime': '2023-06-02', 'open': '514.93500', 'high': '523.00500', 'low': '512.56000', 'close': '520.21002', 'volume': '353352'}], 'status': 'ok'}\n",
      "Symbol: SPX, Response: {'meta': {'symbol': 'SPX', 'interval': '1day', 'currency': 'USD', 'exchange_timezone': 'America/New_York', 'exchange': 'NYSE', 'mic_code': 'XNYS', 'type': 'Index'}, 'values': [{'datetime': '2023-06-02', 'open': '4241.00977', 'high': '4284.77002', 'low': '4241.00977', 'close': '4283.62988', 'volume': '2408870938'}], 'status': 'ok'}\n",
      "Symbol: SPXW, Response: {'message': 'You have exceeded the rate limit per minute for your plan, BASIC, by the API provider'}\n",
      "No volume data found for symbol: SPXW\n",
      "Symbol: UNH, Response: {'message': 'You have exceeded the rate limit per minute for your plan, BASIC, by the API provider'}\n",
      "No volume data found for symbol: UNH\n",
      "Symbol: MDB, Volume: 7218753\n",
      "Symbol: LRCX, Volume: 618287\n",
      "Symbol: CRWD, Volume: 4908974\n",
      "Symbol: LULU, Volume: 7016822\n",
      "Symbol: TGT, Volume: 4638484\n",
      "Symbol: SVIX, Volume: 1488689\n",
      "Symbol: HUM, Volume: 353352\n",
      "Symbol: SPX, Volume: 2408870938\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def compute_positions(start_time):\n",
    "    # Establish a connection to the PostgreSQL database\n",
    "    connection = psycopg2.connect(host=\"10.7.8.59\", database=\"fixtransactions\", user=\"scalp\", password=\"QAtr@de442\", port='5432')\n",
    "    cursor = connection.cursor()\n",
    "    query = f\"\"\"\n",
    "        SELECT clearing_account, symbol, SUM(ABS(quantity)) AS position\n",
    "        FROM trades\n",
    "        WHERE trading_date = timestamp '{start_time}'\n",
    "        AND clearing_account NOT IN ('5646353', '3618282', '3618588', '3616407', '5647492')\n",
    "        AND clearing_account NOT LIKE 'AOS%'\n",
    "        GROUP BY clearing_account, symbol\n",
    "        limit 10\n",
    "        \"\"\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['Trader', 'Underlying', 'Position'])\n",
    "    return df\n",
    "\n",
    "def remove_suffix(symbol):\n",
    "    # Extract the first group of capital letters and remove trailing characters\n",
    "    matches = re.match(r\"([A-Z]+)\", symbol)\n",
    "    if matches:\n",
    "        symbol = matches.group(1)\n",
    "    return symbol\n",
    "\n",
    "date = '2023-06-01'\n",
    "positions = compute_positions(date)\n",
    "\n",
    "# Example usage\n",
    "symbols = positions['Underlying'].tolist()\n",
    "\n",
    "url = \"https://twelve-data1.p.rapidapi.com/time_series\"\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"e902ad106dmsh3e8e389d32866d8p113ddejsnc1b66501d82a\",\n",
    "    \"X-RapidAPI-Host\": \"twelve-data1.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "volumes = {}\n",
    "for symbol in symbols:\n",
    "    symbol = remove_suffix(symbol) \n",
    "    querystring = {\n",
    "        \"symbol\": symbol,\n",
    "        \"interval\": \"1day\",\n",
    "        \"outputsize\": \"1\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    data = response.json()\n",
    "    print(f\"Symbol: {symbol}, Response: {data}\")\n",
    "    \n",
    "    if 'values' in data and len(data['values']) > 0:\n",
    "        volume = data['values'][0]['volume']\n",
    "        volumes[symbol] = volume\n",
    "    else:\n",
    "        print(f\"No volume data found for symbol: {symbol}\")\n",
    "\n",
    "# Print the volumes for each symbol\n",
    "for symbol, volume in volumes.items():\n",
    "    print(f\"Symbol: {symbol}, Volume: {volume}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_605707/1590350055.py:36: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path, options=chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: /home/elliott/Development/scripts/jupyter_notebooks/\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "def download_and_group_volume_data(chrome_driver_path, download_directory):\n",
    "    csv_file_path = os.path.join(download_directory, \"vol-query-results.csv\")\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(csv_file_path):\n",
    "        print(\"File already exists. Skipping download.\")\n",
    "    else:\n",
    "        url = \"https://www.theocc.com/market-data/market-data-reports/volume-and-open-interest/volume-query\"\n",
    "\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_experimental_option(\n",
    "            \"prefs\", {\n",
    "                \"download.default_directory\": download_directory,\n",
    "                \"download.prompt_for_download\": False,\n",
    "                \"download.directory_upgrade\": True,\n",
    "                \"safebrowsing.enabled\": True\n",
    "            }\n",
    "        )\n",
    "\n",
    "        driver = webdriver.Chrome(executable_path=chrome_driver_path, options=chrome_options)\n",
    "        driver.get(url)\n",
    "\n",
    "        # Click on the \"Accept\" button for the cookies banner\n",
    "        accept_cookies_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"body > div.CookieConsent > span.ConsentButtons > a:nth-child(2)\"))\n",
    "        )\n",
    "        accept_cookies_button.click()\n",
    "\n",
    "        # Locate the download button using the XPath and click it\n",
    "        download_button = WebDriverWait(driver, 10).until(\n",
    "            lambda d: d.find_element(By.XPATH, '/html/body/div/main/section/div/div/div[2]/div/div/div[9]/div/a')\n",
    "        )\n",
    "        download_button.click()\n",
    "\n",
    "        # Add some delay to let the download complete (adjust the time as needed)\n",
    "        time.sleep(5)\n",
    "\n",
    "        print(f\"File downloaded to: {download_directory}\")\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    volume_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Group the data by 'underlying' and sum the 'quantity' column\n",
    "    grouped_df = volume_df.groupby('underlying')['quantity'].sum().reset_index()\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "def get_grouped_df(chrome_driver_path, download_directory):\n",
    "    grouped_df = download_and_group_volume_data(chrome_driver_path, download_directory)\n",
    "    grouped_df = grouped_df.rename(columns={'underlying': 'Underlying'})\n",
    "    grouped_df = grouped_df.rename(columns={'quantity': 'Volume'})\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "def compute_positions(start_time):\n",
    "    # Establish a connection to the PostgreSQL database\n",
    "    connection = psycopg2.connect(host=\"10.7.8.59\", database=\"fixtransactions\", user=\"scalp\", password=\"QAtr@de442\", port='5432')\n",
    "    cursor = connection.cursor()\n",
    "    query = f\"\"\"\n",
    "        SELECT clearing_account, symbol, SUM(ABS(quantity)) AS position\n",
    "        FROM trades\n",
    "        WHERE trading_date = timestamp '{start_time}'\n",
    "        AND clearing_account NOT IN ('5646353', '3618282', '3618588', '3616407', '5647492')\n",
    "        AND clearing_account NOT LIKE 'AOS%'\n",
    "        GROUP BY clearing_account, symbol\n",
    "        \"\"\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['Trader', 'Underlying', 'Position'])\n",
    "    return df\n",
    "\n",
    "date = '2023-06-02'\n",
    "chrome_driver_path = \"/usr/bin/chromedriver\"\n",
    "download_directory = \"/home/elliott/Development/scripts/jupyter_notebooks/\"\n",
    "grouped_df = get_grouped_df(chrome_driver_path, download_directory)\n",
    "positions = compute_positions(date)\n",
    "positions.to_csv(\"positions.csv\")\n",
    "merged_df = positions.merge(grouped_df, on='Underlying', how='inner')\n",
    "merged_df['Position'] = merged_df['Position'].astype(float)\n",
    "merged_df['Volume'] = merged_df['Volume'].astype(float)\n",
    "merged_df['Concentration'] = (merged_df['Position'] / merged_df['Volume']) * 100\n",
    "merged_df['Concentration'] = merged_df['Concentration'].round(2)\n",
    "merged_df['Concentration'] = merged_df['Concentration'].map(\"{:.2f}%\".format)\n",
    "merged_df['Concentration'] = merged_df['Concentration'].str.rstrip('%').astype('float')\n",
    "merged_df.sort_values(by='Concentration', axis=0, ascending=False, inplace=True)\n",
    "merged_df.to_csv(f\"concentration_report_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Underlying</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>77512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAC</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AADI</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAIC</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>ZUO</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>ZVRA</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>ZWS</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>ZYME</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4089 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Underlying  Volume\n",
       "0             A     824\n",
       "1            AA   77512\n",
       "2           AAC      10\n",
       "3          AADI      10\n",
       "4          AAIC     234\n",
       "...         ...     ...\n",
       "4084        ZUO     234\n",
       "4085       ZVRA     134\n",
       "4086        ZWS      36\n",
       "4087       ZYME     498\n",
       "4088       ZYXI     106\n",
       "\n",
       "[4089 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: AAPL, Volume: 30522311\n",
      "Symbol: GOOGL, Volume: 12942919\n",
      "Symbol: MSFT, Volume: 11587144\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "symbols = ['AAPL', 'GOOGL', 'MSFT']  # List of symbols\n",
    "\n",
    "url = \"https://twelve-data1.p.rapidapi.com/time_series\"\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"e902ad106dmsh3e8e389d32866d8p113ddejsnc1b66501d82a\",\n",
    "    \"X-RapidAPI-Host\": \"twelve-data1.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "volumes = {}\n",
    "for symbol in symbols:\n",
    "    querystring = {\n",
    "        \"symbol\": symbol,\n",
    "        \"interval\": \"1day\",\n",
    "        \"outputsize\": \"1\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    data = response.json()\n",
    "    \n",
    "    if 'values' in data and len(data['values']) > 0:\n",
    "        volume = data['values'][0]['volume']\n",
    "        volumes[symbol] = volume\n",
    "    else:\n",
    "        print(f\"No volume data found for symbol: {symbol}\")\n",
    "\n",
    "# Print the volumes for each symbol\n",
    "for symbol, volume in volumes.items():\n",
    "    print(f\"Symbol: {symbol}, Volume: {volume}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
